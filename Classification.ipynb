{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Explanations. ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Improving Music Genre Classification using Text Lyrics. \n",
    "\n",
    "Hypothesis: Lyrics does contain important information not shown in the audio itself that can improve audio classifiers.\n",
    "\n",
    "Dataset: Contains Audio Features and Song Lyrics with Music genre as label and artist_and_song as unique identifyer.\n",
    "\n",
    "Preparation: see the two notebooks below containing filtering, analysis and workflow for this project.\n",
    "- data_analysis_for_prototype.ipynb\n",
    "- song_text_data.ipynb\n",
    "\n",
    "Resources: Custom built data set combining datapoints from\n",
    "- Audio Features data: https://www.kaggle.com/datasets/zaheenhamidani/ultimate-spotify-tracks-db\n",
    "- Text Lyrics data: https://www.kaggle.com/datasets/edenbd/150k-lyrics-labeled-with-spotify-valence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and load custom data-set. ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = pd.read_csv('DATASETS/Project_dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor changes and some analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12440"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Country             1738\n",
       "Ska                 1687\n",
       "Blues               1469\n",
       "Folk                1144\n",
       "Dance                995\n",
       "Rock                 917\n",
       "Electronic           911\n",
       "Reggae               864\n",
       "Soul                 804\n",
       "R&B                  469\n",
       "Jazz                 431\n",
       "Pop                  387\n",
       "Hip-Hop              234\n",
       "Indie                152\n",
       "Children’s Music     122\n",
       "Rap                  116\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.genre.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After careful consideration the whole point is to answer the question of this project and therefore I will remove genres below 500 datapoints. I do this because of two reasons:\n",
    "- Analysis and plots will be less congested with overflowing amounts of classes.\n",
    "- Removing classes with too few datapoints will balance out the dataset and make the classification easier for the models.\n",
    "\n",
    "The downside is that the model becomes less general, and not adapted to the real world (where there are many music genres.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Country       1738\n",
       "Ska           1687\n",
       "Blues         1469\n",
       "Folk          1144\n",
       "Dance          995\n",
       "Rock           917\n",
       "Electronic     911\n",
       "Reggae         864\n",
       "Soul           804\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a filter for genres with value counts >= 500\n",
    "valid_genres = data.genre.value_counts()\n",
    "genres_to_keep = valid_genres[valid_genres >= 500].index\n",
    "\n",
    "# Subset the DataFrame based on the filter\n",
    "data = data[data.genre.isin(genres_to_keep)]\n",
    "\n",
    "data.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy accuracy: 17 %\n"
     ]
    }
   ],
   "source": [
    "print('Dummy accuracy:', round(100 * 1738 /len(data) ), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist_and_song</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.387</td>\n",
       "      <td>234307</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>-4.528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>168.105</td>\n",
       "      <td>2</td>\n",
       "      <td>0.674</td>\n",
       "      <td>gary allan /// get off on the pain</td>\n",
       "      <td>I don't know why I love women\\r\\nThat love to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.633</td>\n",
       "      <td>183600</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>-14.090</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>106.111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450</td>\n",
       "      <td>hank williams, jr. /// old habits</td>\n",
       "      <td>I kicked the habit, of smoking back some time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.493</td>\n",
       "      <td>262720</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>-4.127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>119.996</td>\n",
       "      <td>2</td>\n",
       "      <td>0.190</td>\n",
       "      <td>carrie underwood /// chaser</td>\n",
       "      <td>I need something strong tonight\\nI'm needing m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.687</td>\n",
       "      <td>320040</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>-10.151</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>129.296</td>\n",
       "      <td>3</td>\n",
       "      <td>0.807</td>\n",
       "      <td>bobby bare /// the winner</td>\n",
       "      <td>The hulk of a man with a beer in his hand he l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.618</td>\n",
       "      <td>226187</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>-4.973</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>119.987</td>\n",
       "      <td>2</td>\n",
       "      <td>0.545</td>\n",
       "      <td>brooks &amp; dunn /// proud of the house we built</td>\n",
       "      <td>I dropped to my knees in that field on your da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre  acousticness  danceability  duration_ms  energy  instrumentalness  \\\n",
       "0     1        0.0293         0.387       234307   0.874          0.000017   \n",
       "1     1        0.1730         0.633       183600   0.444          0.000003   \n",
       "2     1        0.0600         0.493       262720   0.780          0.000248   \n",
       "3     1        0.7730         0.687       320040   0.543          0.000002   \n",
       "4     1        0.0655         0.618       226187   0.790          0.006410   \n",
       "\n",
       "  key  liveness  loudness mode  speechiness    tempo time_signature  valence  \\\n",
       "0   3    0.1710    -4.528    0       0.0530  168.105              2    0.674   \n",
       "1   5    0.0821   -14.090    0       0.0264  106.111              1    0.450   \n",
       "2   3    0.1920    -4.127    0       0.0485  119.996              2    0.190   \n",
       "3  10    0.7050   -10.151    0       0.0521  129.296              3    0.807   \n",
       "4   9    0.1100    -4.973    0       0.0445  119.987              2    0.545   \n",
       "\n",
       "                                 artist_and_song  \\\n",
       "0             gary allan /// get off on the pain   \n",
       "1              hank williams, jr. /// old habits   \n",
       "2                    carrie underwood /// chaser   \n",
       "3                      bobby bare /// the winner   \n",
       "4  brooks & dunn /// proud of the house we built   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  I don't know why I love women\\r\\nThat love to ...  \n",
       "1  I kicked the habit, of smoking back some time ...  \n",
       "2  I need something strong tonight\\nI'm needing m...  \n",
       "3  The hulk of a man with a beer in his hand he l...  \n",
       "4  I dropped to my knees in that field on your da...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in data.columns:\n",
    "    if col in ['key', 'mode', 'time_signature', 'genre']:\n",
    "\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "        data[col] = data[col].astype(\"category\")\n",
    "\n",
    "data.head()\n",
    "\n",
    "# for col in audio_data.columns:\n",
    "#     if col in categorical_columns:\n",
    "#         audio_data[col] = audio_data[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "1    1738\n",
       "7    1687\n",
       "0    1469\n",
       "4    1144\n",
       "2     995\n",
       "6     917\n",
       "3     911\n",
       "5     864\n",
       "8     804\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.genre.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "12435    8\n",
       "12436    8\n",
       "12437    8\n",
       "12438    8\n",
       "12439    8\n",
       "Name: genre, Length: 10529, dtype: category\n",
       "Categories (9, int64): [0, 1, 2, 3, ..., 5, 6, 7, 8]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.genre"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the datasets for audio and text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.genre\n",
    "audio_data = data.drop(columns=['genre', 'artist_and_song','Lyrics'])\n",
    "\n",
    "# Audio classification train test data.\n",
    "X_train_audio, X_test_audio, y_train_audio, y_test_audio = train_test_split(audio_data, labels, test_size=0.2,random_state=42)\n",
    "\n",
    "# print(X_test_audio)\n",
    "# Create train test data for text classification.\n",
    "idx_train = X_train_audio.index\n",
    "idx_test = X_test_audio.index\n",
    "\n",
    "X_train_text = data.loc[idx_train].Lyrics.tolist()\n",
    "X_test_text = data.loc[idx_test].Lyrics.tolist()\n",
    "y_train_text = y_train_audio.tolist()\n",
    "y_test_text = y_test_audio.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data for Audio classification.\n",
    "scaler = StandardScaler()\n",
    "X_train_audio = scaler.fit_transform(X_train_audio)\n",
    "X_test_audio = scaler.transform(X_test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.41       332\n",
      "           1       0.49      0.68      0.57       366\n",
      "           2       0.43      0.35      0.39       195\n",
      "           3       0.52      0.58      0.55       163\n",
      "           4       0.38      0.37      0.37       225\n",
      "           5       0.47      0.56      0.51       162\n",
      "           6       0.28      0.15      0.20       175\n",
      "           7       0.70      0.76      0.73       333\n",
      "           8       0.27      0.18      0.22       155\n",
      "\n",
      "    accuracy                           0.48      2106\n",
      "   macro avg       0.44      0.45      0.44      2106\n",
      "weighted avg       0.46      0.48      0.47      2106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanbiru/Documents/code/text_mining_project-TDDE16/text_mining_env/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "MLP_clf = MLPClassifier()#hidden_layer_sizes=(256,128,64), max_iter=200)\n",
    "\n",
    "# Train the model\n",
    "MLP_clf.fit(X_train_audio, y_train_audio)\n",
    "MLP_y_pred = MLP_clf.predict(X_test_audio)\n",
    "MLP_y_proba_pred = MLP_clf.predict_proba(X_test_audio)\n",
    "\n",
    "# Calculate the classification report for this fold\n",
    "MLP_report = classification_report(y_test_audio, MLP_y_pred)\n",
    "print(MLP_report)\n",
    "print(MLP_y_proba_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.07      0.13       332\n",
      "           1       0.37      0.73      0.50       366\n",
      "           2       0.32      0.34      0.33       195\n",
      "           3       0.48      0.40      0.43       163\n",
      "           4       0.37      0.39      0.38       225\n",
      "           5       0.38      0.49      0.43       162\n",
      "           6       0.30      0.15      0.20       175\n",
      "           7       0.59      0.69      0.64       333\n",
      "           8       0.24      0.12      0.16       155\n",
      "\n",
      "    accuracy                           0.41      2106\n",
      "   macro avg       0.39      0.38      0.35      2106\n",
      "weighted avg       0.41      0.41      0.37      2106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_clf = GaussianNB()\n",
    "naive_clf.fit(X_train_audio, y_train_audio)\n",
    "\n",
    "naive_y_pred = naive_clf.predict(X_test_audio)\n",
    "\n",
    "# Calculate the classification report for this fold\n",
    "naive_report = classification_report(y_test_audio, naive_y_pred)\n",
    "print(naive_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# tabnet_clf = TabNetClassifier()\n",
    "# tabnet_clf.fit(X_train_audio, y_train_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabnet_y_pred = tabnet_clf.predict(X_test_audio)\n",
    "# tabnet_report = classification_report(y_test_audio, tabnet_y_pred)\n",
    "# print(tabnet_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "# classes_weights = class_weight.compute_sample_weight(\n",
    "#     class_weight='balanced',\n",
    "#     y=audio_data['genre'])\n",
    "\n",
    "xgb_clf.fit(X_train_audio, y_train_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.39      0.41       332\n",
      "           1       0.51      0.63      0.56       366\n",
      "           2       0.43      0.39      0.41       195\n",
      "           3       0.53      0.55      0.54       163\n",
      "           4       0.37      0.41      0.39       225\n",
      "           5       0.48      0.50      0.49       162\n",
      "           6       0.28      0.20      0.23       175\n",
      "           7       0.73      0.76      0.75       333\n",
      "           8       0.30      0.23      0.26       155\n",
      "\n",
      "    accuracy                           0.49      2106\n",
      "   macro avg       0.45      0.45      0.45      2106\n",
      "weighted avg       0.48      0.49      0.48      2106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_y_pred = xgb_clf.predict(X_test_audio)\n",
    "xgb_report = classification_report(y_test_audio, xgb_y_pred)\n",
    "print(xgb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9977007889943236, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=0.002238238469617126, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.03711299495104505, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=447, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9977007889943236, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=0.002238238469617126, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.03711299495104505, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=447, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9977007889943236, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=0.002238238469617126, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.03711299495104505, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=447, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_XGB_params = {\n",
    "                'max_depth': 4,\n",
    "                'learning_rate': 0.03711299495104505,\n",
    "                'n_estimators': 447,\n",
    "                'min_child_weight': 10,\n",
    "                'gamma': 0.002238238469617126,\n",
    "                'subsample': 0.849826493051354,\n",
    "                'colsample_bytree': 0.9977007889943236,\n",
    "                'reg_alpha': 0.15538382519234734,\n",
    "                'reg_lambda': 7.07955517130104e-07,\n",
    "                'enable_categorical' : True,\n",
    "                'tree_method' : \"hist\"\n",
    "               }\n",
    "\n",
    "xgb2_clf = xgb.XGBClassifier(**best_XGB_params)\n",
    "\n",
    "xgb2_clf.fit(X_train_audio, y_train_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.44       332\n",
      "           1       0.50      0.66      0.57       366\n",
      "           2       0.43      0.38      0.40       195\n",
      "           3       0.58      0.64      0.61       163\n",
      "           4       0.39      0.39      0.39       225\n",
      "           5       0.51      0.56      0.53       162\n",
      "           6       0.29      0.16      0.21       175\n",
      "           7       0.74      0.78      0.76       333\n",
      "           8       0.34      0.25      0.28       155\n",
      "\n",
      "    accuracy                           0.51      2106\n",
      "   macro avg       0.47      0.47      0.47      2106\n",
      "weighted avg       0.49      0.51      0.50      2106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb2_y_pred = xgb2_clf.predict(X_test_audio)\n",
    "xgb2_report = classification_report(y_test_audio, xgb2_y_pred)\n",
    "print(xgb2_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# sm = SMOTE(random_state=42)\n",
    "\n",
    "# X_res, y_res = sm.fit_resample(X_train_audio, y_train_audio)\n",
    "\n",
    "# print(\"Inspect oversampling: \\n\",y_res.value_counts())\n",
    "\n",
    "# xgb3_clf = xgb.XGBClassifier()#**best_XGB_params)\n",
    "\n",
    "# xgb3_clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb3_y_pred = xgb3_clf.predict(X_test_audio)\n",
    "# xgb3_report = classification_report(y_test_audio, xgb3_y_pred)\n",
    "# print(xgb3_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabnet2_clf = TabNetClassifier()\n",
    "# tabnet2_clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabnet2_y_pred = tabnet2_clf.predict(X_test_audio)\n",
    "# tabnet2_report = classification_report(y_test_audio, tabnet2_y_pred)\n",
    "# print(tabnet2_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us do prediction on the Lyrics instead! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanbiru/Documents/code/text_mining_project-TDDE16/text_mining_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Some testing \n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# text = X_train_text[120]\n",
    "# print(text)\n",
    "# test = tokenizer(text)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_for_bert(batch, tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')):\n",
    "    \n",
    "    N = len(batch)\n",
    "    texts, final_labels = [0]*N, [0]*N\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        texts[i] = batch[i][0]\n",
    "        final_labels[i] = batch[i][1] \n",
    "\n",
    "    #pad to longest length of longest sentence in batch!\n",
    "    tokenized = tokenizer(texts, padding=True, max_length=512, truncation=True)\n",
    "    #print(tokenized)\n",
    "    token_id = torch.tensor(tokenized['input_ids'])\n",
    "    attention_masks = torch.tensor(tokenized['attention_mask'])\n",
    "    return token_id.to(device), attention_masks.to(device), torch.tensor(final_labels).to(device) \n",
    "\n",
    "# token_id, attention_masks, labels = processing_for_bert(X_train_text[:2], y_train_text[:2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_list(list):\n",
    "    list_len = [len(i) for i in list]\n",
    "    return max(list_len)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions\n",
    "def accuracy(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    #print(pred_flat)\n",
    "    #print(labels_flat)\n",
    "    return np.sum(preds_flat == labels_flat)/len(preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_map(num_categories):\n",
    "\n",
    "    #mapping for labels\n",
    "    zero_vec = [0] * num_categories \n",
    "    label_map = {}\n",
    "    for i in range(num_categories-1):\n",
    "        gold_vec = zero_vec.copy()\n",
    "        gold_vec[i] = 1\n",
    "        label_map[i] = gold_vec\n",
    "    # print(label_map)\n",
    "    return label_map\n",
    "\n",
    "def create_text_data(X,Y):\n",
    "    \"\"\"Create data of shape [(x1,y1), (x2,y2),...,]\"\"\"\n",
    "    data = []\n",
    "    for i in range(len(X)):\n",
    "        data.append((X[i],Y[i]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, n_epochs=1, batch_size=32, lr=1e-5):\n",
    "    \"\"\"\n",
    "    Train a BERT classifier on the provided training data.\n",
    "\n",
    "    Parameters:\n",
    "    - train_data (torch.utils.data.Dataset): Training dataset.\n",
    "    - n_epochs (int, optional): Number of training epochs. Default is 1.\n",
    "    - batch_size (int, optional): Batch size. Default is 32.\n",
    "    - lr (float, optional): Learning rate. Default is 1e-5.\n",
    "\n",
    "    Returns:\n",
    "    - classifier (torch.nn.Module): Trained BERT classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Nine music genres\n",
    "    num_categories = 9  \n",
    "\n",
    "    # Prepare the data loaders\n",
    "    train_loader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=processing_for_bert)\n",
    "\n",
    "    # Build the classifier\n",
    "    classifier = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_categories).to(device)\n",
    "\n",
    "    # Initialise the optimizer\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    try:\n",
    "        for epoch in range(n_epochs):\n",
    "            train_losses = 0\n",
    "            classifier.train()\n",
    "            for batch in tqdm(train_loader):\n",
    "                train_token_id = batch[0]\n",
    "                train_attention_masks = batch[1]\n",
    "                train_labels = batch[2]\n",
    "\n",
    "                # Reset the accumulated gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                output = classifier(train_token_id,\n",
    "                                    token_type_ids=None,\n",
    "                                    attention_mask=train_attention_masks,\n",
    "                                    labels=train_labels)\n",
    "\n",
    "                # Save loss\n",
    "                train_losses += output.loss.item()\n",
    "\n",
    "                # Backward pass; propagates the loss and computes the gradients\n",
    "                output.loss.backward()\n",
    "                # Update the parameters of the model\n",
    "                optimizer.step()\n",
    "\n",
    "            print('epoch_avg_train_loss:', round(train_losses / len(train_loader), 3))\n",
    "\n",
    "        # Save model parameters\n",
    "        torch.save(classifier.state_dict(), 'trained_model.pth')\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(classifier, test_data, batch_size=32):\n",
    "    \"\"\"\n",
    "    Evaluate the classifier on test data, returning classification report and class probabilities.\n",
    "    \n",
    "    Parameters:\n",
    "    - classifier (torch.nn.Module): Model to evaluate.\n",
    "    - test_data (torch.utils.data.Dataset): Test dataset.\n",
    "    - batch_size (int, optional): Batch size. Default is 32.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple:\n",
    "        - report (str): Classification report.\n",
    "        - all_probs_tensor (torch.Tensor): Predicted class probabilities.\n",
    "    \"\"\"   \n",
    "    test_loader = DataLoader(test_data, batch_size, collate_fn=processing_for_bert)\n",
    "\n",
    "    classifier.eval()\n",
    "\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            val_token_id = batch[0]\n",
    "            val_attention_masks = batch[1]\n",
    "            val_labels = batch[2]\n",
    "\n",
    "            output = classifier(val_token_id,\n",
    "                                token_type_ids=None,\n",
    "                                attention_mask=val_attention_masks,\n",
    "                                labels=val_labels)\n",
    "\n",
    "            # Convert logits to probabilities using softmax\n",
    "            probs = F.softmax(output.logits, dim=1)\n",
    "            all_probs.append(probs)\n",
    "\n",
    "            # Store predictions and true labels for computing the weighted F1 later\n",
    "            preds_flat = np.argmax(output.logits.detach().cpu().numpy(), axis=1)\n",
    "            all_preds.extend(preds_flat.tolist())\n",
    "            all_labels.extend(val_labels.to('cpu').numpy().tolist())\n",
    "\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "        \n",
    "    all_probs_tensor = torch.cat(all_probs, dim=0)\n",
    "    return report, all_probs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_data = create_text_data(X_train_text, y_train_text)\n",
    "text_test_data = create_text_data(X_test_text, y_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  1%|          | 3/264 [09:59<14:29:28, 199.88s/it]\n"
     ]
    }
   ],
   "source": [
    "model = train_model(text_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "/Users/hanbiru/Documents/code/text_mining_project-TDDE16/text_mining_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hanbiru/Documents/code/text_mining_project-TDDE16/text_mining_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hanbiru/Documents/code/text_mining_project-TDDE16/text_mining_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hanbiru/Documents/code/text_mining_project-TDDE16/text_mining_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hanbiru/Documents/code/text_mining_project-TDDE16/text_mining_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hanbiru/Documents/code/text_mining_project-TDDE16/text_mining_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report, text_pred_probs = test_model(model, text_test_data[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09162419 0.17112213 0.09888737 0.11190072 0.08715122 0.07841507\n",
      "  0.06692923 0.21866548 0.0753045 ]\n",
      " [0.08354866 0.303768   0.06471396 0.0613597  0.08798452 0.05442909\n",
      "  0.10990866 0.17746    0.05682735]]\n"
     ]
    }
   ],
   "source": [
    "# Save the array\n",
    "np.save('text_pred_probs.npy', text_pred_probs)\n",
    "# Load the numpy array\n",
    "loaded_probs_array = np.load('text_pred_probs.npy')\n",
    "print(loaded_probs_array)\n",
    "# Convert the numpy array back to a tensor if needed\n",
    "loaded_probs_tensor = torch.tensor(loaded_probs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.20      1.00      0.33         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20         5\n",
      "   macro avg       0.04      0.20      0.07         5\n",
      "weighted avg       0.04      0.20      0.07         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, num_categories=9):\n",
    "    \"\"\"\n",
    "    Load the trained BERT classifier from the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path (str): Path to the saved model parameters.\n",
    "    - num_categories (int, optional): Number of output categories. Default is 9.\n",
    "\n",
    "    Returns:\n",
    "    - classifier (torch.nn.Module): Loaded BERT classifier.\n",
    "    \"\"\"\n",
    "    # Build the classifier\n",
    "    classifier = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_categories)\n",
    "\n",
    "    # Load the model parameters\n",
    "    classifier.load_state_dict(torch.load(model_path))\n",
    "    classifier.eval()  # Set the model to evaluation mode\n",
    "    return classifier\n",
    "\n",
    "# Usage:\n",
    "# Assuming you have saved the model using the train_model function\n",
    "loaded_model = load_model('trained_model.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2576a6d18678760ed6536f546e22b496d0bed3c16ff3f1d390fa8bfc056e9f3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
